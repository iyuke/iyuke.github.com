---
layout: post
title: 算法设计思想
date: 2017-09-25 13:32:20 +0300
description: You’ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. # Add post description (optional)
img: how-to-start.jpg # Add image post (optional)
tags: [academic]
---
Don't be jealous of others. Because you never know how much you will get in the next second. 

### 判断URL是否在黑名单上

布隆过滤器的话适用于系统容忍一定程度的失误率，但是对空间要求比较严格，它可以用很少的空间将准确率做的很高。布隆过滤器是基于哈希函数的，一个优秀的哈希函数能够做到很多不同的输入值所得到的返回值非常均匀的分布在S上，那么将所有的返回值对m取余，可以认为所有的返回值都非常均匀地分布在0~m-1上。布隆过滤器的大小m的话由公式确定,p为误差率
> m = -n * lnp / ((ln2) ^ 2)

哈希函数的个数是k = 0.7 * m / n

### 有一个包含20亿个全是32位整数的大文件，在其中找到次数最多的数
把包含20亿个数的大文件用哈希函数分成16个小文件，根据哈希函数的性质，同一种数不可能被哈希到不同的小文件上，同时每个小文件中不同的数一定不会超过2亿种，假设哈希函数足够好，然后对每一个小文件用哈希表来统计初其中每种数出现的次数，哈希表key占用4B，value占用4B，当哈希表记录为2亿时，需要至少1.6G内存。

### 40亿个非负整数找到没出现的数
1.最多使用1G内存     bitmap
2.最多用10M，但只要找到一个没出现的数即可   把40亿个数先分成64个区，申请一个new int[64]大小的数组，遍历40亿个数，来决定哪个区间计数增加，遍历完成后，必然会有一个位置小于67108864，再遍历一次这40亿个数，同时使用bitmap，对这个区间 上的数统计，申请67108864长度的bitmap，大约8M

### 找到100亿个URL中重复的URL以及搜索词汇的top K问题
把大文件通过哈希函数分配到不同机器，或者通过哈希函数把大文件拆成小文件，哈希函数的性质决定了同一条URL不可能分给不同的机器，再对每一个小文件进行哈希表遍历，找到重复的URL。Top K问题也一样，通过分流，再统计各自的top K，最后再合并。

### 40个亿非负整数中找到出现两次的数字
用bitmap，但是每个数字占用2个bit，大约1G

### 一致性哈希算法
这么问题在做分布式缓存的时候存在，当用memcache搭建分布式缓存的时候，如果增加或者移除一台机器，那么所有的数据就不得不根据id重新计算一遍哈希值，并将哈希值对新的机器数进行取模操作，然后进行大规模的数据迁移。一致性哈希算法的话，首先我们假设数据的id 通过哈希函数转换成哈希值范围是2^32，数字头尾相连，形成一个环。将机器映射到这个环上，数字也映射到这个环上，然后顺时针寻找离这个位置最近的机器，就是归属，当新增一台机器时，把添加后的统一归与这台新增的管，并且把一部分旧数据从其他及其迁徙过来，调整代价小。为了解决数据倾斜，一致性哈希算法还引入了虚拟节点机制，每一台机器通过不同的哈希函数计算出多个哈希值，多个位置多放置一台服务节点，称为虚拟节点。




